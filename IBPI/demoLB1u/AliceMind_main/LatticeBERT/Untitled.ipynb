{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "497c95cf-21ba-4374-9539-a14aecc3c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "from run_sequence_labeling_crf_labert import FLAGS, SequenceLabelingProcessor, model_fn_builder,modeling,tokenization_labert,file_based_convert_examples_to_features,file_based_input_fn_builder\n",
    "import tensorflow as tf\n",
    "import modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7e5904d-115c-4a62-a7a0-2bf91191bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_checkpoint = '/home/ops/jupyter/语义/dataprocess/摘要-标题-图谱/内容理解/Lattice_Bert/tmp/best/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "369c4d28-0799-4727-8990-2da3ca151df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x7f5984b48630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.compat.v1.app.flags.DEFINE_string('f', '', 'kernel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8af373cb-9dec-4d45-81d2-5abf4d545ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fcc34354-8ddf-4e5b-83be-0869e28ea213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1a796d09-6677-49b6-8bb9-52c391032970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:number of lexicon entries: 79145\n",
      "INFO:tensorflow:number of vocab entries: 101985\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f578468b730>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/ops/jupyter/语义/dataprocess/摘要-标题-图谱/内容理解/Lattice_Bert/tmp/best/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/home/ops/jupyter/语义/dataprocess/摘要-标题-图谱/内容理解/Lattice_Bert/chinese_labert-lite-std-512/'\n",
    "FLAGS.labert_config_file= base_dir + 'labert_config.json'\n",
    "FLAGS.vocab_file = base_dir + 'vocab.txt'\n",
    "FLAGS.lexicon_file = base_dir + 'lexicon.txt'\n",
    "FLAGS.label_file = base_dir + '../tmp/labels.pkl'\n",
    "FLAGS.init_checkpoint = init_checkpoint\n",
    "labert_config = modeling.BertConfig.from_json_file(FLAGS.labert_config_file)\n",
    "label_list = pickle.load(open(FLAGS.label_file, 'rb'))\n",
    "processor = SequenceLabelingProcessor()\n",
    "processor.set_labels(label_list)\n",
    "pos_indices = [index for index, label in enumerate(label_list) if label.lower() != 'o']\n",
    "\n",
    "\n",
    "num_train_steps = None\n",
    "num_warmup_steps = None\n",
    "save_checkpoints_steps = 1000\n",
    "\n",
    "\n",
    "tokenizer = tokenization_labert.LatticeTokenizer(\n",
    "      vocab_file=FLAGS.vocab_file,\n",
    "      lexicon_file=FLAGS.lexicon_file,\n",
    "      do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "is_per_host = tf.compat.v1.estimator.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.compat.v1.estimator.tpu.RunConfig(\n",
    "                master=None,\n",
    "                # model_dir=init_checkpoint,\n",
    "                save_checkpoints_steps=save_checkpoints_steps,\n",
    "                keep_checkpoint_max=1,\n",
    "                log_step_count_steps=1 << 25,\n",
    "                tpu_config=tf.compat.v1.estimator.tpu.TPUConfig(\n",
    "                  iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "                  num_shards=8,\n",
    "                  per_host_input_for_training=is_per_host))\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    labert_config=labert_config,\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=False,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    beta1=FLAGS.adam_beta1,\n",
    "    beta2=FLAGS.adam_beta2,\n",
    "    epsilon=FLAGS.adam_epsilon,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    lr_layer_decay_rate=FLAGS.lr_layer_decay_rate,\n",
    "    pos_indices=pos_indices)\n",
    "\n",
    "    # If TPU is not available, this will fall back to normal Estimator on CPU\n",
    "    # or GPU.\n",
    "estimator = tf.compat.v1.estimator.tpu.TPUEstimator(\n",
    "          model_dir = init_checkpoint,\n",
    "          use_tpu=False,\n",
    "          model_fn=model_fn,\n",
    "          config=run_config,\n",
    "          predict_batch_size=FLAGS.predict_batch_size)\n",
    "\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b1e29-5b81-4c0e-8521-555f9ddd2bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d5392902-4826-47b7-9ec8-2fca4744c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-0\n",
      "INFO:tensorflow:tokens: [CLS] 美 纹 纸 真 的 让 人 又 爱 又 恨 ！ 真的 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 5400 5291 5290 4695 4637 6374 781 1347 4262 1347 2615 8012 21234 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:positional_embeddings_start: 0 1 2 3 4 5 6 7 8 9 10 11 12 4 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:positional_embeddings_end: 0 1 2 3 4 5 6 7 8 9 10 11 12 5 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_positions: 1 2 3 4 5 6 7 8 9 10 11 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-1\n",
      "INFO:tensorflow:tokens: [CLS] 又 爱 又 恨 ！ [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1347 4262 1347 2615 8012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:positional_embeddings_start: 0 1 2 3 4 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:positional_embeddings_end: 0 1 2 3 4 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_positions: 1 2 3 4 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:***** Running prediction *****\n",
      "INFO:tensorflow:  Num examples = 2 (2 actual, 0 padding)\n",
      "INFO:tensorflow:  Batch size = 8\n",
      "INFO:tensorflow:***** Predict results *****\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU/GPU\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ops/jupyter/语义/dataprocess/摘要-标题-图谱/内容理解/Lattice_Bert/tmp/best/model.ckpt-414\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "contents_predict(estimator, test_file, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bc45b021-872a-448c-9fef-9b84dbc9d091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object TPUEstimator.predict at 0x7f58e0570200>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "faa08e39-ab52-4479-ba9d-7a85644707a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '/home/ops/jupyter/语义/dataprocess/摘要-标题-图谱/内容理解/Lattice_Bert/predict/test.txt'\n",
    "out_file = os.path.dirname(test_file) + '/pre.txt'\n",
    "def contents_predict(estimator,test_file ,out_file):\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "    tpu_cluster_resolver = None\n",
    "\n",
    "    predict_examples = processor._create_examples(processor.get_raw_data(test_file), \"test\")\n",
    "    # predict_examples = processor.get_test_examples(test_file)\n",
    "    num_actual_predict_examples = len(predict_examples)\n",
    "    predict_file = os.path.join(os.path.dirname(test_file), \"predict.tf_record\")\n",
    "    file_based_convert_examples_to_features(\n",
    "      predict_examples, label_list, FLAGS.max_seq_length, tokenizer, predict_file)\n",
    "\n",
    "    tf.compat.v1.logging.info(\"***** Running prediction *****\")\n",
    "    tf.compat.v1.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
    "                              len(predict_examples), num_actual_predict_examples,\n",
    "                              len(predict_examples) - num_actual_predict_examples)\n",
    "    tf.compat.v1.logging.info(\"  Batch size = %d\", FLAGS.predict_batch_size)\n",
    "\n",
    "    predict_input_fn = file_based_input_fn_builder(\n",
    "        input_file=predict_file,\n",
    "        seq_length=FLAGS.max_seq_length,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    result = estimator.predict(input_fn=predict_input_fn)\n",
    "\n",
    "    with tf.io.gfile.GFile(out_file, \"w\") as writer:\n",
    "        num_written_lines = 0\n",
    "        tf.compat.v1.logging.info(\"***** Predict results *****\")\n",
    "        for (i, prediction) in enumerate(result):\n",
    "            predictions = prediction[\"predictions\"]\n",
    "            label_weights = prediction[\"label_weights\"]\n",
    "            if i >= num_actual_predict_examples:\n",
    "                break\n",
    "            output_line = \"\\n\".join(label_list[tag]\n",
    "                for k, tag in enumerate(predictions) if label_weights[k] > 0.) + \"\\n\\n\"\n",
    "            writer.write(output_line)\n",
    "            num_written_lines += 1\n",
    "    assert num_written_lines == num_actual_predict_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3a03a825-abe2-499e-b539-361bc9bfab81",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'input_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-f47ccf4d2d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'input_fn'"
     ]
    }
   ],
   "source": [
    "estimator.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19562caa-3aea-4325-9e73-9cd1c5d82ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833e88c-9c5a-4a37-b621-46205c7753ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf0b13-43fd-481d-a783-14ab28f842ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "predict_examples = processor._create_examples(processor.get_raw_data(test_file), \"test\")\n",
    "# predict_examples = processor.get_test_examples(test_file)\n",
    "num_actual_predict_examples = len(predict_examples)\n",
    "predict_file = os.path.join(os.path.dirname(test_file), \"predict.tf_record\")\n",
    "file_based_convert_examples_to_features(\n",
    "  predict_examples, label_list, FLAGS.max_seq_length, tokenizer, predict_file)\n",
    "\n",
    "\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "result = estimator.predict(input_fn=predict_input_fn)\n",
    "\n",
    "with tf.io.gfile.GFile(out_file, \"w\") as writer:\n",
    "    num_written_lines = 0\n",
    "    tf.compat.v1.logging.info(\"***** Predict results *****\")\n",
    "    for (i, prediction) in enumerate(result):\n",
    "        print(1)\n",
    "        predictions = prediction[\"predictions\"]\n",
    "        label_weights = prediction[\"label_weights\"]\n",
    "        if i >= num_actual_predict_examples:\n",
    "            break\n",
    "        output_line = \"\\n\".join(label_list[tag]\n",
    "            for k, tag in enumerate(predictions) if label_weights[k] > 0.) + \"\\n\\n\"\n",
    "        writer.write(output_line)\n",
    "        num_written_lines += 1\n",
    "assert num_written_lines == num_actual_predict_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a78e92-863a-4005-9d8d-1e791f83662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "predict_examples = processor._create_examples(processor.get_raw_data(test_file), \"test\")\n",
    "# predict_examples = processor.get_test_examples(test_file)\n",
    "num_actual_predict_examples = len(predict_examples)\n",
    "predict_file = os.path.join(os.path.dirname(test_file), \"predict.tf_record\")\n",
    "file_based_convert_examples_to_features(\n",
    "  predict_examples, label_list, FLAGS.max_seq_length, tokenizer, predict_file)\n",
    "\n",
    "\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "result = estimator.predict(input_fn=predict_input_fn)\n",
    "\n",
    "with tf.io.gfile.GFile(out_file, \"w\") as writer:\n",
    "    num_written_lines = 0\n",
    "    tf.compat.v1.logging.info(\"***** Predict results *****\")\n",
    "    for (i, prediction) in enumerate(result):\n",
    "        predictions = prediction[\"predictions\"]\n",
    "        label_weights = prediction[\"label_weights\"]\n",
    "        if i >= num_actual_predict_examples:\n",
    "            break\n",
    "        output_line = \"\\n\".join(label_list[tag]\n",
    "            for k, tag in enumerate(predictions) if label_weights[k] > 0.) + \"\\n\\n\"\n",
    "        writer.write(output_line)\n",
    "        num_written_lines += 1\n",
    "assert num_written_lines == num_actual_predict_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cfe76-c8b5-4d73-aaaf-10d741dab70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = estimator.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9fa97-4096-43e2-b0e6-03b3f572fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f09db424-bf12-45fe-aa82-53f7e42c411a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-0\n",
      "INFO:tensorflow:tokens: [CLS] 美 纹 纸 真 的 让 人 又 爱 又 恨 ！ 真的 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 5400 5291 5290 4695 4637 6374 781 1347 4262 1347 2615 8012 21234 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:positional_embeddings_start: 0 1 2 3 4 5 6 7 8 9 10 11 12 4 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:positional_embeddings_end: 0 1 2 3 4 5 6 7 8 9 10 11 12 5 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_positions: 1 2 3 4 5 6 7 8 9 10 11 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-1\n",
      "INFO:tensorflow:tokens: [CLS] 又 爱 又 恨 ！ [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1347 4262 1347 2615 8012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:positional_embeddings_start: 0 1 2 3 4 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:positional_embeddings_end: 0 1 2 3 4 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_positions: 1 2 3 4 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object TPUEstimator.predict at 0x7f58e0570360>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_examples = processor._create_examples(processor.get_raw_data(test_file), \"test\")\n",
    "# predict_examples = processor.get_test_examples(test_file)\n",
    "num_actual_predict_examples = len(predict_examples)\n",
    "predict_file = os.path.join(os.path.dirname(test_file), \"predict.tf_record\")\n",
    "file_based_convert_examples_to_features(\n",
    "  predict_examples, label_list, FLAGS.max_seq_length, tokenizer, predict_file)\n",
    "\n",
    "\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "result = estimator.predict(input_fn=predict_input_fn)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc489aa6-ffba-42e4-ae8d-bf7717a0b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7f7dfc19-c089-461b-a5d8-6a85da350c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Predict results *****\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU/GPU\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ops/jupyter/语义/dataprocess/摘要-标题-图谱/内容理解/Lattice_Bert/tmp/best/model.ckpt-414\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "num_written_lines = 0\n",
    "tf.compat.v1.logging.info(\"***** Predict results *****\")\n",
    "for (i, prediction) in enumerate(result):\n",
    "    predictions = prediction[\"predictions\"]\n",
    "    label_weights = prediction[\"label_weights\"]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1a5f47fa-1773-491f-a7b3-53b09a55b293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_per_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71630e0-f0b5-4cf5-bb3f-b6c1033c3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c66425a-dd23-4dc6-b525-6586549d733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.compat.v1.estimator.tpu.RunConfig()\n",
    "zz = tf.compat.v1.estimator.tpu.TPUConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40e2bbd-001c-40a3-815e-cb4cc9700f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.distribute.mirrored_strategy.MirroredStrategyV1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.distribute.MirroredStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cee630ee-9527-4667-b6fc-0c1d8ee1143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.distribute.cross_device_ops import AllReduceCrossDeviceOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c73fd5-f953-4a8a-a84f-97d64478faec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "zz = tf.compat.v1.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02883e1-58df-465e-847b-fa2b35021b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllReduceCrossDeviceOps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad5628b-c277-4c52-ab4b-9c01325092a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.mirrored_strategy.MirroredStrategyV1 at 0x7f5e9abc5a58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.distribute.MirroredStrategy(\n",
    "        devices=[\"/gpu:0\",\"/gpu:1\"],\n",
    "        cross_device_ops=AllReduceCrossDeviceOps('nccl', num_packs=2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b11596d-36d5-4bda-a19a-38d07e15a175",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'model_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-68ebd7bb3907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maaa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'model_fn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "aaa = tf.compat.v1.estimator.Estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4aa47c-91d5-47eb-ae94-b74aea189c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ops/jupyter/语义/dataprocess/摘要-标题-图谱/内容理解/Lattice_Bert/AliceMind_main/LatticeBERT'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b94f2c-905a-4f4b-a32e-68b519d1e1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-qiushi",
   "language": "python",
   "name": "python3-qiushi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
